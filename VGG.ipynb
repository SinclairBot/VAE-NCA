{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import os\n",
    "import cv2\n",
    "import time\n",
    "import pickle\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from IPython.display import clear_output\n",
    "from datetime import datetime\n",
    "\n",
    "from lib.utils import make_seed, make_circle_masks\n",
    "from lib.utils import get_living_mask, get_sobel, softmax, to_rgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VAE_encoder(nn.Module):\n",
    "    \n",
    "    def __init__(self, dim_out):\n",
    "        super(VAE_encoder, self).__init__()\n",
    "        self.conv_mu    = nn.Sequential(nn.Conv2d(3,64,7,padding=3,stride=1), nn.ReLU(),\n",
    "                                        nn.MaxPool2d(2,stride=2),\n",
    "                                        nn.Conv2d(64,64,3,padding=1), nn.ReLU(),\n",
    "                                        nn.Conv2d(64,64,3,padding=1), nn.ReLU(),\n",
    "                                        nn.Conv2d(64,64,3,padding=1), nn.ReLU(),\n",
    "                                        nn.MaxPool2d(2,stride=2),\n",
    "                                        nn.Conv2d(64,128,3,padding=1), nn.ReLU(),\n",
    "                                        nn.Conv2d(128,128,3,padding=1), nn.ReLU(),\n",
    "                                        nn.Conv2d(128,128,3,padding=1), nn.ReLU(),\n",
    "                                        nn.MaxPool2d(2,stride=2),\n",
    "                                        nn.Conv2d(128,256,3,padding=1), nn.ReLU(),\n",
    "                                        nn.Conv2d(256,256,3,stride=1,padding=1), nn.ReLU(),\n",
    "                                        nn.Conv2d(256,512,5,stride=2,padding=2), nn.ReLU(),\n",
    "                                        nn.Conv2d(512,1024,3))\n",
    "        self.lin_mu     = nn.Linear(1024,dim_out)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        c_mu = self.conv_mu(x)\n",
    "        c_mu = torch.reshape(c_mu, [-1,1024])\n",
    "        return self.lin_mu(c_mu)\n",
    "    \n",
    "class VAE_decoder(nn.Module):\n",
    "    \n",
    "    def __init__(self, dim_in, dim_out):\n",
    "        super(VAE_decoder, self).__init__()\n",
    "        self.lin = nn.Sequential(nn.Linear(dim_in,dim_in*2), nn.ReLU(),\n",
    "                                 nn.Linear(dim_in*2,dim_in*2), nn.ReLU(),\n",
    "                                 nn.Linear(dim_in*2,dim_in*2), nn.ReLU(),\n",
    "                                 nn.Linear(dim_in*2,dim_in*2), nn.ReLU(),\n",
    "                                 nn.Linear(dim_in*2,dim_out))\n",
    "        \n",
    "    def forward(self, z):\n",
    "        r = self.lin(z)\n",
    "        return r\n",
    "    \n",
    "class GNCAModel(nn.Module):\n",
    "\n",
    "    def __init__(self, sobels, channel_n, alpha_channel,\n",
    "                 fire_rate=0.5, calibration=1.0, device=torch.device(\"cpu\")):\n",
    "        super(GNCAModel, self).__init__()\n",
    "\n",
    "        self.sobels = sobels\n",
    "        self.device = device\n",
    "        self.channel_n = channel_n\n",
    "        self.alpha_channel = alpha_channel\n",
    "        \n",
    "        self.pool = torch.nn.MaxPool2d(kernel_size=3, padding=1, stride=1)\n",
    "\n",
    "        self.fire_rate = fire_rate\n",
    "        self.calibration = calibration\n",
    "        self.to(self.device)\n",
    "\n",
    "    def perceive(self, x, angle):\n",
    "\n",
    "        def _perceive_with(x, weight):\n",
    "            size = weight.shape[0]\n",
    "            padding = (size-1)/2\n",
    "            conv_weights = torch.from_numpy(weight.astype(np.float32)).to(self.device)\n",
    "            conv_weights = conv_weights.view(1,1,size,size).repeat(self.channel_n, 1, 1, 1)\n",
    "            return F.conv2d(x, conv_weights, padding=int(padding), groups=self.channel_n)\n",
    "\n",
    "        ys = [x,self.pool(x)]\n",
    "        for sobel in self.sobels:\n",
    "            wa_1, wa_2 = get_sobel(sobel)\n",
    "            wa_1/=np.sum(np.abs(wa_1))\n",
    "            wa_2/=np.sum(np.abs(wa_2))\n",
    "            y1 = _perceive_with(x, wa_1)\n",
    "            y2 = _perceive_with(x, wa_2)\n",
    "            ys.append(y1)\n",
    "            ys.append(y2)\n",
    "        y = torch.cat(ys,1)\n",
    "        return y\n",
    "    \n",
    "    def linear(self, x, w, b=None):\n",
    "        original_shape = x.size()\n",
    "        batch = x.size(0)\n",
    "        y = torch.reshape(x, [batch,-1,original_shape[-1]]).to(self.device)\n",
    "        if b is None:\n",
    "            y = torch.bmm(y, w)\n",
    "        else:\n",
    "            y = torch.bmm(y, w)+b\n",
    "        y = torch.reshape(y, list(original_shape[:-1])+[y.size(-1)])\n",
    "        return y\n",
    "\n",
    "    def update(self, x, params, fire_rate, angle):\n",
    "        w0, b0, w1 = params\n",
    "        \n",
    "        x = x.transpose(1,3)\n",
    "        pre_life_mask = get_living_mask(x, self.alpha_channel, 3)\n",
    "\n",
    "        dx = self.perceive(x, angle)\n",
    "        dx = dx.transpose(1,3)\n",
    "        dx = self.linear(dx, w0, b0)\n",
    "        dx = F.relu(dx)\n",
    "        dx = self.linear(dx, w1)\n",
    "\n",
    "        if fire_rate is None:\n",
    "            fire_rate=self.fire_rate\n",
    "        stochastic = torch.rand([dx.size(0),dx.size(1),dx.size(2),1])>fire_rate\n",
    "        stochastic = stochastic.float().to(self.device)\n",
    "        dx = dx * stochastic\n",
    "        dx = dx.transpose(1,3)\n",
    "\n",
    "        x = x+dx\n",
    "\n",
    "        post_life_mask = get_living_mask(x, self.alpha_channel, 3)\n",
    "        life_mask = (pre_life_mask & post_life_mask).float()\n",
    "        \n",
    "        x = x * life_mask\n",
    "        x = x.transpose(1,3)\n",
    "        return x\n",
    "\n",
    "    def forward(self, x, params, steps, calibration_map=None, fire_rate=None, angle=0.0):\n",
    "        history = [x.detach().cpu().clamp(0.0, 1.0).numpy(),]\n",
    "        for step in range(steps):\n",
    "            x = self.update(x, params, fire_rate, angle)\n",
    "            if calibration_map is not None:\n",
    "                h = x[..., :(self.alpha_channel+1)]\n",
    "                t = calibration_map[..., :(self.alpha_channel+1)]\n",
    "                _delta = t*(h-1)\n",
    "                delta = _delta * self.calibration * (calibration_map!=0).float()\n",
    "                _x = x[..., :(self.alpha_channel+1)]-delta\n",
    "                x = torch.cat((_x,x[..., (self.alpha_channel+1):]), -1)\n",
    "            history.append(x.detach().cpu().clamp(0.0, 1.0).numpy())\n",
    "        return x, history\n",
    "    \n",
    "class model_VAE(nn.Module):\n",
    "    \n",
    "    def __init__(self, sobels, hidden_encoder, hidden_channel_n, channel_n, size, alpha_channel,\n",
    "                 device=torch.device(\"cpu\")):\n",
    "        super(model_VAE, self).__init__()\n",
    "        self.sobels = sobels\n",
    "        self.channel_n = channel_n\n",
    "        self.hidden_channel_n = hidden_channel_n\n",
    "        self.size = size\n",
    "        self.alpha_channel = alpha_channel\n",
    "        self.eps = 1e-3\n",
    "        \n",
    "        self.encoder = VAE_encoder(hidden_encoder)\n",
    "        self.decoder_w0 = VAE_decoder(hidden_encoder, channel_n*(len(self.sobels)+1)*2*self.hidden_channel_n)\n",
    "        self.decoder_b0 = VAE_decoder(hidden_encoder, self.hidden_channel_n)\n",
    "        self.decoder_w1 = VAE_decoder(hidden_encoder, self.hidden_channel_n*channel_n)\n",
    "        self.GNCA = GNCAModel(self.sobels, self.channel_n, self.alpha_channel, device=device)\n",
    "        \n",
    "        self.device = device\n",
    "        self.to(self.device)\n",
    "    \n",
    "    def encode(self, x):\n",
    "        z = self.encoder(x)\n",
    "        return z\n",
    "    \n",
    "    def decode(self, z):\n",
    "        w0 = self.decoder_w0(z)\n",
    "        b0 = self.decoder_b0(z)\n",
    "        w1 = self.decoder_w1(z)\n",
    "        params = (torch.reshape(w0,[-1,self.channel_n*(len(self.sobels)+1)*2,self.hidden_channel_n]),\n",
    "                  torch.reshape(b0,[-1,1,self.hidden_channel_n]),\n",
    "                  torch.reshape(w1,[-1,self.hidden_channel_n,self.channel_n]))\n",
    "        return params\n",
    "    \n",
    "    def infer(self, x0, x, steps, calibration_map=None):\n",
    "        with torch.no_grad():\n",
    "            x_ = torch.reshape(x, [-1,self.alpha_channel,self.size,self.size])\n",
    "            z = self.encode(x_)\n",
    "            params = self.decode(z)\n",
    "            y, history = self.GNCA(x0, params, steps, calibration_map=calibration_map)\n",
    "            y = y[..., :(self.alpha_channel+1)].clamp(self.eps, 1.0-self.eps)\n",
    "        return y, history\n",
    "    \n",
    "    def multi_infer(self, x0, xs, steps, gamma=0.99, calibration_map=None):\n",
    "        with torch.no_grad():\n",
    "            params_list = []\n",
    "            zs = []\n",
    "            for x in xs:\n",
    "                x_ = torch.reshape(x, [-1,self.alpha_channel,self.size,self.size])\n",
    "                z = self.encode(x_)\n",
    "                zs.append(z.detach().cpu().numpy())\n",
    "                params = self.decode(z)\n",
    "                params_list.append(params)\n",
    "            y = x0\n",
    "            history = [x0.detach().cpu().numpy()]\n",
    "            for i in range(steps):\n",
    "                y, _ = self.GNCA(y, params_list[i%len(params_list)], 1, calibration_map=calibration_map)\n",
    "                his = y[..., :(self.alpha_channel+1)].clamp(self.eps, 1.0-self.eps).detach().cpu().numpy()\n",
    "                history.append(his)\n",
    "            y = y[..., :(self.alpha_channel+1)].clamp(self.eps, 1.0-self.eps)\n",
    "        return y, history, zs\n",
    "    \n",
    "    def train(self, x0, x, target, steps, beta, calibration_map=None):\n",
    "        x_ = torch.reshape(x, [-1,self.alpha_channel,self.size,self.size])\n",
    "        z = self.encode(x_)\n",
    "        params = self.decode(z)\n",
    "        y_raw, _ = self.GNCA(x0, params, steps, calibration_map=calibration_map)\n",
    "        y_raw = y_raw.clamp(self.eps, 1.0-self.eps)\n",
    "        y = y_raw[..., :(self.alpha_channel+1)]\n",
    "        \n",
    "        mse = F.mse_loss(y, target)\n",
    "        l2 = torch.sum(torch.pow(z, 2))\n",
    "        loss = mse + beta*l2\n",
    "        \n",
    "        return y_raw, loss, (mse.item(), l2.item())\n",
    "\n",
    "def read_and_resize(path, size):\n",
    "    raw=mpimg.imread(path)\n",
    "    scale = size/min(raw.shape[0], raw.shape[1])\n",
    "    new_shape = (max(int(raw.shape[1]*scale),64), max(int(raw.shape[0]*scale),64))\n",
    "    img = cv2.resize(raw, new_shape)\n",
    "    img = img[(img.shape[0]-size)//2:(img.shape[0]-size)//2+size,\n",
    "              (img.shape[1]-size)//2:(img.shape[1]-size)//2+size, :]\n",
    "    return img\n",
    "\n",
    "def plot_loss(loss_log):\n",
    "    plt.figure(figsize=(10, 4))\n",
    "    plt.title('Loss history (log10)')\n",
    "    plt.plot(np.log10(loss_log), '.', alpha=0.1)\n",
    "    plt.show()\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ROOT = \"/disk2/mingxiang_workDir/vggface2/test/\"\n",
    "SIZE = 40\n",
    "\n",
    "DEVICE = torch.device(\"cuda:0\")\n",
    "model_path = \"models/gen_AE_vgg2.pth\"\n",
    "init_coord = (SIZE//2, SIZE//2)\n",
    "\n",
    "SOBEL_SIZES = [3,5,9]\n",
    "ALPHA_CHANNEL = 3\n",
    "HIDDEN_ENCODER = 1024\n",
    "CHANNEL_N = 24\n",
    "HIDDEN_CHANNEL_N = 256\n",
    "\n",
    "BATCH_SIZE = 8\n",
    "N_STEPS = 160\n",
    "\n",
    "names = [x for x in os.listdir(ROOT) if x[0]!='.']\n",
    "paths = {}\n",
    "for name in names:\n",
    "    paths[name] = [x for x in os.listdir(ROOT+name) if x[0]!='.']\n",
    "print(\"num_images\", np.sum([len(paths[name]) for name in names]))\n",
    "\n",
    "my_model = model_VAE(SOBEL_SIZES, HIDDEN_ENCODER, HIDDEN_CHANNEL_N, CHANNEL_N,\n",
    "                     SIZE, ALPHA_CHANNEL, device=DEVICE)\n",
    "my_model.load_state_dict(torch.load(model_path))\n",
    "\n",
    "loss_log = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "n_batch = 8\n",
    "for index in range(n_batch):\n",
    "    name_batch = np.random.choice(len(names), BATCH_SIZE, replace=False)\n",
    "    path_is = [np.random.randint(len(paths[names[names_i]])) for names_i in name_batch]\n",
    "    x_np = []\n",
    "    for i in range(len(name_batch)):\n",
    "        name = names[name_batch[i]]\n",
    "        path = ROOT+name+\"/\"+paths[name][path_is[i]]\n",
    "        x_np.append(read_and_resize(path, SIZE))\n",
    "    x_np = np.array(x_np).transpose([0,3,1,2])/255.0\n",
    "    x_np = x_np.astype(np.float32)\n",
    "\n",
    "    x = torch.from_numpy(x_np).to(DEVICE)\n",
    "    target_np = x_np.reshape([-1, ALPHA_CHANNEL, SIZE, SIZE]).transpose([0,2,3,1])\n",
    "    alpha_values = np.expand_dims(np.ones(target_np.shape[:-1]), -1)\n",
    "    target_np = np.concatenate([target_np, alpha_values], -1)\n",
    "\n",
    "    seed = make_seed((SIZE,SIZE), CHANNEL_N, np.arange(CHANNEL_N-ALPHA_CHANNEL)+ALPHA_CHANNEL, init_coord)\n",
    "    x0_np = np.repeat(seed[None, ...], len(name_batch), 0)\n",
    "    x0 = torch.from_numpy(x0_np.astype(np.float32)).to(DEVICE)\n",
    "\n",
    "    y, history = my_model.infer(x0, x, N_STEPS)\n",
    "    y = y.detach().cpu().numpy()\n",
    "\n",
    "    i_shows = [i for i in range(BATCH_SIZE)]\n",
    "    plt.figure(figsize=(18,5))\n",
    "    for i,ii in enumerate(i_shows):\n",
    "        plt.subplot(2,len(i_shows),i+1)\n",
    "        plt.imshow(to_rgb(target_np[ii]))\n",
    "        plt.axis('off')\n",
    "    for i,ii in enumerate(i_shows):\n",
    "        plt.subplot(2,len(i_shows),i+len(i_shows)+1)\n",
    "        plt.imshow(to_rgb(y[ii,...,:(ALPHA_CHANNEL+1)]))\n",
    "        plt.axis('off')\n",
    "    plt.show()\n",
    "    print(\"----------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "n_batch = 1\n",
    "for index in range(n_batch):\n",
    "    name_batch = np.random.choice(len(names), BATCH_SIZE, replace=False)\n",
    "    path_is = [np.random.randint(len(paths[names[names_i]])) for names_i in name_batch]\n",
    "    x_np = []\n",
    "    for i in range(len(name_batch)):\n",
    "        name = names[name_batch[i]]\n",
    "        path = ROOT+name+\"/\"+paths[name][path_is[i]]\n",
    "        x_np.append(read_and_resize(path, SIZE))\n",
    "    x_np = np.array(x_np).transpose([0,3,1,2])/255.0\n",
    "    x_np_raw = x_np.astype(np.float32)\n",
    "    \n",
    "    damages = []\n",
    "    for _ in range(BATCH_SIZE):\n",
    "        n_damage = 8\n",
    "        damage = 1.0-make_circle_masks(n_damage, SIZE, SIZE, rmin=0.02, rmax=0.05)\n",
    "        damage = np.sum(damage, 0)>=n_damage\n",
    "        damages.append(damage)\n",
    "    damages = np.array(damages)[:, None, ...]\n",
    "    x_np = x_np.astype(np.float32)*damages\n",
    "\n",
    "    x = torch.from_numpy(x_np).to(DEVICE)\n",
    "    \n",
    "    target_np_raw = x_np_raw.reshape([-1, ALPHA_CHANNEL, SIZE, SIZE]).transpose([0,2,3,1])\n",
    "    alpha_values = np.expand_dims(np.ones(target_np_raw.shape[:-1]), -1)\n",
    "    target_np_raw = np.concatenate([target_np_raw, alpha_values], -1)\n",
    "    \n",
    "    target_np = x_np.reshape([-1, ALPHA_CHANNEL, SIZE, SIZE]).transpose([0,2,3,1])\n",
    "    alpha_values = np.expand_dims(np.ones(target_np.shape[:-1]), -1)\n",
    "    target_np = np.concatenate([target_np, alpha_values], -1)\n",
    "\n",
    "    seed = make_seed((SIZE,SIZE), CHANNEL_N, np.arange(CHANNEL_N-ALPHA_CHANNEL)+ALPHA_CHANNEL, init_coord)\n",
    "    x0_np = np.repeat(seed[None, ...], len(name_batch), 0)\n",
    "    x0 = torch.from_numpy(x0_np.astype(np.float32)).to(DEVICE)\n",
    "\n",
    "    y, history = my_model.infer(x0, x, N_STEPS)\n",
    "    y = y.detach().cpu().numpy()\n",
    "\n",
    "    i_shows = [i for i in range(BATCH_SIZE)]\n",
    "    plt.figure(figsize=(18,5))\n",
    "    for i,ii in enumerate(i_shows):\n",
    "        plt.subplot(3,len(i_shows),i+1)\n",
    "        plt.imshow(to_rgb(target_np_raw[ii]))\n",
    "        plt.axis('off')\n",
    "    for i,ii in enumerate(i_shows):\n",
    "        plt.subplot(3,len(i_shows),i+len(i_shows)+1)\n",
    "        plt.imshow(to_rgb(target_np[ii]))\n",
    "        plt.axis('off')\n",
    "    for i,ii in enumerate(i_shows):\n",
    "        plt.subplot(3,len(i_shows),i+len(i_shows)*2+1)\n",
    "        plt.imshow(to_rgb(y[ii,...,:(ALPHA_CHANNEL+1)]))\n",
    "        plt.axis('off')\n",
    "    plt.show()\n",
    "    print(\"----------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:py37_torch] *",
   "language": "python",
   "name": "conda-env-py37_torch-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
